{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "FILENAME = \"train.csv\"\n",
    "df = pd.read_csv(FILENAME)x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "duplicates = df.duplicated()\n",
    "print(\"Number of duplicate rows: \", duplicates.sum())\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "X = df.drop(\"Year\", axis=1)\n",
    "y = df[\"Year\"]\n",
    "\n",
    "print(\"Questa è la variabile X  \\n\")\n",
    "print(X.shape)\n",
    "print(\"\\n\\nQuesta è la variabile y  \\n\")\n",
    "print(y.shape)\n",
    "total_nan_rows = df.isna().any(axis=1).sum()\n",
    "\n",
    "\n",
    "print(\"Number of Nan Rows: \", total_nan_rows)\n",
    "\n",
    "\n",
    "num_rows, num_cols = df.shape\n",
    "print(\"Number of rows: \", num_rows)\n",
    "print(\"Number of columns: \", num_cols)\n",
    "\n",
    "plt.hist(df['Year'])\n",
    "plt.xlabel('Anno di pubblicazione')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.title('Distribuzione anno di pubblicazione')\n",
    "plt.show()\n",
    "\n",
    "matrix_corr = df.corr()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(matrix_corr, annot=False, cmap='coolwarm', fmt=\".2f\",linewidths=.5, xticklabels=False, yticklabels=False, cbar=False)\n",
    "plt.title('Matrice di Correlazione')\n",
    "plt.show()\n",
    "\n",
    "matrix_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(X)\n",
    "plt.title('Box Plot delle Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "# a function with different normalization and scaling techniques\n",
    "def preprocessTrain(X_train, X_test, modality):\n",
    "    \n",
    "    X_train_p = X_train\n",
    "    X_test_p = X_test\n",
    "\n",
    "    if modality == 'standard':\n",
    "        file = open(file=\"standardScaler.save\", mode=\"wb\")\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        pickle.dump(obj=scaler, file=file)\n",
    "        X_train_p = scaler.transform(X_train)\n",
    "        X_test_p = scaler.transform(X_test)\n",
    "        \n",
    "    if modality == 'min-max':\n",
    "        file = open(file=\"minMaxScaler.save\", mode=\"wb\")\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        pickle.dump(obj=scaler, file=file)\n",
    "        X_train_p = scaler.transform(X_train)\n",
    "        X_test_p = scaler.transform(X_test)\n",
    "        \n",
    "    return X_train_p, X_test_p\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy import stats\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Esegui lo split in set di addestramento, di test e di validazione\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=seed)\n",
    "\n",
    "pre = ['No', 'standard', 'min-max']\n",
    "hyperparameters = itertools.product(pre)\n",
    "\n",
    "def score(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return r2_score(y, y_pred)\n",
    "\n",
    "best_r2 = -np.inf\n",
    "best_preprocessing = 'No'\n",
    "best_model = None\n",
    "\n",
    "for preprocessing_type in pre:\n",
    "    # Preprocess\n",
    "    X_train_p, X_val_p = preprocessTrain(X_train, X_val, preprocessing_type)\n",
    "    \n",
    "    # Initialize Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train_p, y_train)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_r2 = score(model, X_val_p, y_val)\n",
    "    \n",
    "    print(\"Validation R-squared: {:.3f}\".format(val_r2), \"Preprocessing =\", preprocessing_type)\n",
    "    \n",
    "    # Save best result so far\n",
    "    if val_r2 > best_r2:\n",
    "        best_r2 = val_r2\n",
    "        best_preprocessing = preprocessing_type\n",
    "        best_model = model\n",
    "\n",
    "print(\"\\nBest Preprocessing:\", best_preprocessing)\n",
    "\n",
    "\n",
    "# Final training and testing\n",
    "X_train_p, X_test_p = preprocessTrain(X_train, X_test, \"standard\")\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_p, y_train)\n",
    "\n",
    "file = open(\"regression.save\",\"wb\")\n",
    "pickle.dump(model, file)\n",
    "file.close()\n",
    "\n",
    "y_test_pred = model.predict(X_test_p)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = np.mean(np.abs(y_test - y_test_pred))\n",
    "mape_test = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100\n",
    "\n",
    "# Print results\n",
    "print(\"\\nTest set MSE: {:.2f}\".format(mse_test))\n",
    "print(\"Test set R-squared: {:.2f}\".format(r2_test))\n",
    "print(\"Test set MAE: {:.2f}\".format(mae_test))\n",
    "print(\"Test set MAPE: {:.2f}%\".format(mape_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Supponendo che tu abbia già definito X e y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "pre = ['No', 'standard', 'min-max']\n",
    "n_estimators_values = [50, 100, 150]  # Modifica il numero di stimatori se necessario\n",
    "hyperparameters = list(itertools.product(pre, n_estimators_values))\n",
    "\n",
    "def score(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return r2_score(y, y_pred)\n",
    "\n",
    "best_r2 = -np.inf\n",
    "best_preprocessing = 'No'\n",
    "best_n_estimators = 0\n",
    "best_model = None\n",
    "\n",
    "for preprocessing_type, n_estimators in hyperparameters:\n",
    "    # Preprocess\n",
    "    X_train_p, X_val_p = preprocessTrain(X_train, X_val, preprocessing_type)\n",
    "    \n",
    "    # Initialize Random Forest Regressor model\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train_p, y_train)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_r2 = score(model, X_val_p, y_val)\n",
    "    \n",
    "    print(\"Validation R-squared: {:.3f}\".format(val_r2), \"Preprocessing =\", preprocessing_type, \"n_estimators =\", n_estimators)\n",
    "    \n",
    "    # Save best result so far\n",
    "    if val_r2 > best_r2:\n",
    "        best_r2 = val_r2\n",
    "        best_preprocessing = preprocessing_type\n",
    "        best_n_estimators = n_estimators\n",
    "        best_model = model\n",
    "\n",
    "print(\"\\nBest Preprocessing:\", best_preprocessing)\n",
    "print(\"Best n_estimators:\", best_n_estimators)\n",
    "\n",
    "# Final training and testing with best hyperparameters\n",
    "X_train_p_best, X_test_p_best = preprocessTrain(X_train, X_test, best_preprocessing)\n",
    "final_model = RandomForestRegressor(n_estimators=best_n_estimators, random_state=42)\n",
    "final_model.fit(X_train_p_best, y_train)\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open(\"randomForestReg.save\", \"wb\") as file:\n",
    "    pickle.dump(final_model, file)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = final_model.predict(X_test_p_best)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = np.mean(np.abs(y_test - y_test_pred))\n",
    "mape_test = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100\n",
    "\n",
    "# Print results\n",
    "print(\"\\nTest set MSE: {:.2f}\".format(mse_test))\n",
    "print(\"Test set R-squared: {:.2f}\".format(r2_test))\n",
    "print(\"Test set MAE: {:.2f}\".format(mae_test))\n",
    "print(\"Test set MAPE: {:.2f}%\".format(mape_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Supponendo che tu abbia già definito X e y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "Cs = [0.01, 0.1, 1, 10, 100]\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "hyperparameters = list(itertools.product(kernels, Cs))\n",
    "\n",
    "def score(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return r2_score(y, y_pred)\n",
    "\n",
    "best_r2 = -np.inf\n",
    "best_C = 0\n",
    "best_kernel = 'linear'\n",
    "best_model = None\n",
    "\n",
    "for kernel, C in hyperparameters:\n",
    "    # Preprocess\n",
    "    X_train_p, X_val_p = preprocessTrain(X_train, X_val, \"min_max\")\n",
    "    \n",
    "    # Initialize SVR model\n",
    "    model = SVR(kernel=kernel, C=C)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train_p, y_train)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_r2 = score(model, X_val_p, y_val)\n",
    "    \n",
    "    print(\"Validation R-squared: {:.3f}\".format(val_r2), \"Kernel =\", kernel, \"C =\", C)\n",
    "    \n",
    "    # Save best result so far\n",
    "    if val_r2 > best_r2:\n",
    "        best_r2 = val_r2\n",
    "        best_C = C\n",
    "        best_kernel = kernel\n",
    "        best_model = model\n",
    "\n",
    "print(\"\\nBest C value:\", best_C)\n",
    "print(\"Best Kernel:\", best_kernel)\n",
    "\n",
    "# Final training and testing with best hyperparameters\n",
    "X_train_p_best, X_test_p_best = preprocessTrain(X_train, X_test, \"min_max\")\n",
    "final_model = SVR(kernel=best_kernel, C=best_C)\n",
    "final_model.fit(X_train_p_best, y_train)\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open(\"svr_model.save\", \"wb\") as file:\n",
    "    pickle.dump(final_model, file)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = final_model.predict(X_test_p_best)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = np.mean(np.abs(y_test - y_test_pred))\n",
    "mape_test = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100\n",
    "\n",
    "# Print results\n",
    "print(\"\\nTest set MSE: {:.2f}\".format(mse_test))\n",
    "print(\"Test set R-squared: {:.2f}\".format(r2_test))\n",
    "print(\"Test set MAE: {:.2f}\".format(mae_test))\n",
    "print(\"Test set MAPE: {:.2f}%\".format(mape_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import preprocessing as sk_preprocessing\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "seed = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "pre = ['No', 'standard', 'min-max']\n",
    "n_neighbors_values = [5, 7, 9, 11]  # Modifica i valori secondo le tue esigenze\n",
    "hyperparameters = list(itertools.product(pre, n_neighbors_values))\n",
    "\n",
    "def score(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return r2_score(y, y_pred)\n",
    "\n",
    "best_r2 = -np.inf\n",
    "best_preprocessing = 'No'\n",
    "best_n_neighbors = 0\n",
    "best_model = None\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for preprocessing_type, n_neighbors in hyperparameters:\n",
    "    # Preprocess\n",
    "    X_train_p, X_val_p = preprocessTrain(X_train, X_val, preprocessing_type)\n",
    "    \n",
    "    # Initialize KNN Regressor model\n",
    "    model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train_p, y_train)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_r2 = score(model, X_val_p, y_val)\n",
    "    \n",
    "    print(\"Validation R-squared: {:.3f}\".format(val_r2), \"Preprocessing =\", preprocessing_type, \"n_neighbors =\", n_neighbors)\n",
    "    \n",
    "    # Save best result so far\n",
    "    if val_r2 > best_r2:\n",
    "        best_r2 = val_r2\n",
    "        best_preprocessing = preprocessing_type\n",
    "        best_n_neighbors = n_neighbors\n",
    "        best_model = model\n",
    "\n",
    "print(\"\\nBest Preprocessing:\", best_preprocessing)\n",
    "print(\"Best n_neighbors:\", best_n_neighbors)\n",
    "\n",
    "\n",
    "X_train_p, X_test_p = preprocessTrain(X_train, X_test, \"min-max\")\n",
    "model = KNeighborsRegressor(n_neighbors=11)\n",
    "model.fit(X_train_p, y_train)\n",
    "\n",
    "file = open(\"kNeighborReg.save\",\"wb\")\n",
    "pickle.dump(model, file)\n",
    "file.close()\n",
    "\n",
    "y_test_pred = model.predict(X_test_p)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = np.mean(np.abs(y_test - y_test_pred))\n",
    "mape_test = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100\n",
    "\n",
    "# Print results\n",
    "print(\"\\nTest set MSE: {:.2f}\".format(mse_test))\n",
    "print(\"Test set R-squared: {:.2f}\".format(r2_test))\n",
    "print(\"Test set MAE: {:.2f}\".format(mae_test))\n",
    "print(\"Test set MAPE: {:.2f}%\".format(mape_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
