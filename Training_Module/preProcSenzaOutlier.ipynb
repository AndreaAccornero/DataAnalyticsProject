{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing definitivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Librerie utilizzate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caricamento del dataset e visualizzazione delle principali informazioni:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>S0</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>S7</th>\n",
       "      <th>S8</th>\n",
       "      <th>...</th>\n",
       "      <th>S80</th>\n",
       "      <th>S81</th>\n",
       "      <th>S82</th>\n",
       "      <th>S83</th>\n",
       "      <th>S84</th>\n",
       "      <th>S85</th>\n",
       "      <th>S86</th>\n",
       "      <th>S87</th>\n",
       "      <th>S88</th>\n",
       "      <th>S89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007</td>\n",
       "      <td>44.76752</td>\n",
       "      <td>114.82099</td>\n",
       "      <td>3.83239</td>\n",
       "      <td>27.99928</td>\n",
       "      <td>1.49153</td>\n",
       "      <td>-15.90853</td>\n",
       "      <td>28.24844</td>\n",
       "      <td>3.61650</td>\n",
       "      <td>-7.24653</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.89619</td>\n",
       "      <td>-471.02844</td>\n",
       "      <td>411.56205</td>\n",
       "      <td>443.01198</td>\n",
       "      <td>19.30254</td>\n",
       "      <td>309.07806</td>\n",
       "      <td>-336.91706</td>\n",
       "      <td>-14.70547</td>\n",
       "      <td>-474.44157</td>\n",
       "      <td>31.32820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>52.28942</td>\n",
       "      <td>75.73319</td>\n",
       "      <td>11.35941</td>\n",
       "      <td>-6.20582</td>\n",
       "      <td>-27.64559</td>\n",
       "      <td>-30.75995</td>\n",
       "      <td>12.50955</td>\n",
       "      <td>7.47877</td>\n",
       "      <td>9.88498</td>\n",
       "      <td>...</td>\n",
       "      <td>4.57060</td>\n",
       "      <td>1.36110</td>\n",
       "      <td>-6.52977</td>\n",
       "      <td>59.48672</td>\n",
       "      <td>3.69790</td>\n",
       "      <td>-36.92252</td>\n",
       "      <td>44.08077</td>\n",
       "      <td>3.39993</td>\n",
       "      <td>-70.07591</td>\n",
       "      <td>3.86143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>33.81773</td>\n",
       "      <td>-139.07371</td>\n",
       "      <td>134.19332</td>\n",
       "      <td>17.85216</td>\n",
       "      <td>63.47408</td>\n",
       "      <td>-25.28005</td>\n",
       "      <td>-34.65911</td>\n",
       "      <td>-5.99135</td>\n",
       "      <td>1.27848</td>\n",
       "      <td>...</td>\n",
       "      <td>54.16608</td>\n",
       "      <td>15.04530</td>\n",
       "      <td>39.09107</td>\n",
       "      <td>39.03041</td>\n",
       "      <td>3.68708</td>\n",
       "      <td>-61.88547</td>\n",
       "      <td>45.68115</td>\n",
       "      <td>6.39822</td>\n",
       "      <td>3.24471</td>\n",
       "      <td>35.74749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>41.60866</td>\n",
       "      <td>3.17811</td>\n",
       "      <td>-3.97174</td>\n",
       "      <td>23.53564</td>\n",
       "      <td>-19.68553</td>\n",
       "      <td>20.74407</td>\n",
       "      <td>18.80866</td>\n",
       "      <td>6.24474</td>\n",
       "      <td>-7.98424</td>\n",
       "      <td>...</td>\n",
       "      <td>28.08591</td>\n",
       "      <td>295.88684</td>\n",
       "      <td>54.02395</td>\n",
       "      <td>102.02880</td>\n",
       "      <td>40.47711</td>\n",
       "      <td>15.10258</td>\n",
       "      <td>-250.32293</td>\n",
       "      <td>2.81288</td>\n",
       "      <td>56.05172</td>\n",
       "      <td>3.60432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>44.49525</td>\n",
       "      <td>-32.25270</td>\n",
       "      <td>58.08217</td>\n",
       "      <td>3.73684</td>\n",
       "      <td>-32.53274</td>\n",
       "      <td>-18.72885</td>\n",
       "      <td>-15.85665</td>\n",
       "      <td>-3.34607</td>\n",
       "      <td>22.63786</td>\n",
       "      <td>...</td>\n",
       "      <td>31.44988</td>\n",
       "      <td>-136.50457</td>\n",
       "      <td>-85.11989</td>\n",
       "      <td>-74.96342</td>\n",
       "      <td>9.56921</td>\n",
       "      <td>-100.61689</td>\n",
       "      <td>-133.29315</td>\n",
       "      <td>9.19246</td>\n",
       "      <td>-97.37953</td>\n",
       "      <td>30.11015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252170</th>\n",
       "      <td>1993</td>\n",
       "      <td>46.19915</td>\n",
       "      <td>12.97202</td>\n",
       "      <td>29.32321</td>\n",
       "      <td>12.49879</td>\n",
       "      <td>-14.88763</td>\n",
       "      <td>-14.60964</td>\n",
       "      <td>-9.07813</td>\n",
       "      <td>-4.77650</td>\n",
       "      <td>14.45143</td>\n",
       "      <td>...</td>\n",
       "      <td>5.18055</td>\n",
       "      <td>-68.43144</td>\n",
       "      <td>-255.37766</td>\n",
       "      <td>-19.92673</td>\n",
       "      <td>-20.46062</td>\n",
       "      <td>-64.44939</td>\n",
       "      <td>-564.09909</td>\n",
       "      <td>13.39130</td>\n",
       "      <td>-126.59750</td>\n",
       "      <td>34.17522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252171</th>\n",
       "      <td>2008</td>\n",
       "      <td>45.57508</td>\n",
       "      <td>-30.83634</td>\n",
       "      <td>-9.13791</td>\n",
       "      <td>7.80413</td>\n",
       "      <td>-0.41150</td>\n",
       "      <td>-2.97301</td>\n",
       "      <td>2.22720</td>\n",
       "      <td>-15.02186</td>\n",
       "      <td>5.78416</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.11588</td>\n",
       "      <td>-29.11996</td>\n",
       "      <td>43.99473</td>\n",
       "      <td>172.10433</td>\n",
       "      <td>27.92205</td>\n",
       "      <td>-25.05652</td>\n",
       "      <td>-176.00554</td>\n",
       "      <td>11.80790</td>\n",
       "      <td>-217.53687</td>\n",
       "      <td>-37.22642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252172</th>\n",
       "      <td>1979</td>\n",
       "      <td>48.18397</td>\n",
       "      <td>-19.28290</td>\n",
       "      <td>35.40170</td>\n",
       "      <td>-4.43572</td>\n",
       "      <td>-35.35641</td>\n",
       "      <td>-1.80437</td>\n",
       "      <td>-2.59621</td>\n",
       "      <td>-0.31640</td>\n",
       "      <td>-0.13533</td>\n",
       "      <td>...</td>\n",
       "      <td>12.08210</td>\n",
       "      <td>-101.94608</td>\n",
       "      <td>104.57106</td>\n",
       "      <td>56.94138</td>\n",
       "      <td>-6.47794</td>\n",
       "      <td>32.00236</td>\n",
       "      <td>-91.34596</td>\n",
       "      <td>-3.85441</td>\n",
       "      <td>63.39848</td>\n",
       "      <td>-5.69944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252173</th>\n",
       "      <td>1995</td>\n",
       "      <td>29.99863</td>\n",
       "      <td>-35.84167</td>\n",
       "      <td>58.65438</td>\n",
       "      <td>21.15740</td>\n",
       "      <td>17.93387</td>\n",
       "      <td>25.19035</td>\n",
       "      <td>-27.95186</td>\n",
       "      <td>14.64049</td>\n",
       "      <td>-10.70063</td>\n",
       "      <td>...</td>\n",
       "      <td>32.86108</td>\n",
       "      <td>-324.89056</td>\n",
       "      <td>109.56178</td>\n",
       "      <td>133.21987</td>\n",
       "      <td>-8.94126</td>\n",
       "      <td>159.61415</td>\n",
       "      <td>175.69657</td>\n",
       "      <td>7.00635</td>\n",
       "      <td>-102.02967</td>\n",
       "      <td>16.69539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252174</th>\n",
       "      <td>1988</td>\n",
       "      <td>38.77358</td>\n",
       "      <td>28.76751</td>\n",
       "      <td>3.20268</td>\n",
       "      <td>-3.45853</td>\n",
       "      <td>-24.13094</td>\n",
       "      <td>-16.15170</td>\n",
       "      <td>-6.12772</td>\n",
       "      <td>-9.97229</td>\n",
       "      <td>18.25481</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.72540</td>\n",
       "      <td>13.57308</td>\n",
       "      <td>-75.19978</td>\n",
       "      <td>43.74653</td>\n",
       "      <td>5.05338</td>\n",
       "      <td>100.37312</td>\n",
       "      <td>-176.40529</td>\n",
       "      <td>17.35391</td>\n",
       "      <td>104.51010</td>\n",
       "      <td>-34.71013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252175 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year        S0         S1         S2        S3        S4        S5  \\\n",
       "0       2007  44.76752  114.82099    3.83239  27.99928   1.49153 -15.90853   \n",
       "1       2004  52.28942   75.73319   11.35941  -6.20582 -27.64559 -30.75995   \n",
       "2       2005  33.81773 -139.07371  134.19332  17.85216  63.47408 -25.28005   \n",
       "3       1998  41.60866    3.17811   -3.97174  23.53564 -19.68553  20.74407   \n",
       "4       1987  44.49525  -32.25270   58.08217   3.73684 -32.53274 -18.72885   \n",
       "...      ...       ...        ...        ...       ...       ...       ...   \n",
       "252170  1993  46.19915   12.97202   29.32321  12.49879 -14.88763 -14.60964   \n",
       "252171  2008  45.57508  -30.83634   -9.13791   7.80413  -0.41150  -2.97301   \n",
       "252172  1979  48.18397  -19.28290   35.40170  -4.43572 -35.35641  -1.80437   \n",
       "252173  1995  29.99863  -35.84167   58.65438  21.15740  17.93387  25.19035   \n",
       "252174  1988  38.77358   28.76751    3.20268  -3.45853 -24.13094 -16.15170   \n",
       "\n",
       "              S6        S7        S8  ...       S80        S81        S82  \\\n",
       "0       28.24844   3.61650  -7.24653  ...  -1.89619 -471.02844  411.56205   \n",
       "1       12.50955   7.47877   9.88498  ...   4.57060    1.36110   -6.52977   \n",
       "2      -34.65911  -5.99135   1.27848  ...  54.16608   15.04530   39.09107   \n",
       "3       18.80866   6.24474  -7.98424  ...  28.08591  295.88684   54.02395   \n",
       "4      -15.85665  -3.34607  22.63786  ...  31.44988 -136.50457  -85.11989   \n",
       "...          ...       ...       ...  ...       ...        ...        ...   \n",
       "252170  -9.07813  -4.77650  14.45143  ...   5.18055  -68.43144 -255.37766   \n",
       "252171   2.22720 -15.02186   5.78416  ...  -5.11588  -29.11996   43.99473   \n",
       "252172  -2.59621  -0.31640  -0.13533  ...  12.08210 -101.94608  104.57106   \n",
       "252173 -27.95186  14.64049 -10.70063  ...  32.86108 -324.89056  109.56178   \n",
       "252174  -6.12772  -9.97229  18.25481  ... -23.72540   13.57308  -75.19978   \n",
       "\n",
       "              S83       S84        S85        S86       S87        S88  \\\n",
       "0       443.01198  19.30254  309.07806 -336.91706 -14.70547 -474.44157   \n",
       "1        59.48672   3.69790  -36.92252   44.08077   3.39993  -70.07591   \n",
       "2        39.03041   3.68708  -61.88547   45.68115   6.39822    3.24471   \n",
       "3       102.02880  40.47711   15.10258 -250.32293   2.81288   56.05172   \n",
       "4       -74.96342   9.56921 -100.61689 -133.29315   9.19246  -97.37953   \n",
       "...           ...       ...        ...        ...       ...        ...   \n",
       "252170  -19.92673 -20.46062  -64.44939 -564.09909  13.39130 -126.59750   \n",
       "252171  172.10433  27.92205  -25.05652 -176.00554  11.80790 -217.53687   \n",
       "252172   56.94138  -6.47794   32.00236  -91.34596  -3.85441   63.39848   \n",
       "252173  133.21987  -8.94126  159.61415  175.69657   7.00635 -102.02967   \n",
       "252174   43.74653   5.05338  100.37312 -176.40529  17.35391  104.51010   \n",
       "\n",
       "             S89  \n",
       "0       31.32820  \n",
       "1        3.86143  \n",
       "2       35.74749  \n",
       "3        3.60432  \n",
       "4       30.11015  \n",
       "...          ...  \n",
       "252170  34.17522  \n",
       "252171 -37.22642  \n",
       "252172  -5.69944  \n",
       "252173  16.69539  \n",
       "252174 -34.71013  \n",
       "\n",
       "[252175 rows x 91 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILENAME = \"train.csv\"\n",
    "df = pd.read_csv(FILENAME)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252175, 91) \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252175 entries, 0 to 252174\n",
      "Data columns (total 91 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Year    252175 non-null  int64  \n",
      " 1   S0      252175 non-null  float64\n",
      " 2   S1      252175 non-null  float64\n",
      " 3   S2      252175 non-null  float64\n",
      " 4   S3      252175 non-null  float64\n",
      " 5   S4      252175 non-null  float64\n",
      " 6   S5      252175 non-null  float64\n",
      " 7   S6      252175 non-null  float64\n",
      " 8   S7      252175 non-null  float64\n",
      " 9   S8      252175 non-null  float64\n",
      " 10  S9      252175 non-null  float64\n",
      " 11  S10     252175 non-null  float64\n",
      " 12  S11     252175 non-null  float64\n",
      " 13  S12     252175 non-null  float64\n",
      " 14  S13     252175 non-null  float64\n",
      " 15  S14     252175 non-null  float64\n",
      " 16  S15     252175 non-null  float64\n",
      " 17  S16     252175 non-null  float64\n",
      " 18  S17     252175 non-null  float64\n",
      " 19  S18     252175 non-null  float64\n",
      " 20  S19     252175 non-null  float64\n",
      " 21  S20     252175 non-null  float64\n",
      " 22  S21     252175 non-null  float64\n",
      " 23  S22     252175 non-null  float64\n",
      " 24  S23     252175 non-null  float64\n",
      " 25  S24     252175 non-null  float64\n",
      " 26  S25     252175 non-null  float64\n",
      " 27  S26     252175 non-null  float64\n",
      " 28  S27     252175 non-null  float64\n",
      " 29  S28     252175 non-null  float64\n",
      " 30  S29     252175 non-null  float64\n",
      " 31  S30     252175 non-null  float64\n",
      " 32  S31     252175 non-null  float64\n",
      " 33  S32     252175 non-null  float64\n",
      " 34  S33     252175 non-null  float64\n",
      " 35  S34     252175 non-null  float64\n",
      " 36  S35     252175 non-null  float64\n",
      " 37  S36     252175 non-null  float64\n",
      " 38  S37     252175 non-null  float64\n",
      " 39  S38     252175 non-null  float64\n",
      " 40  S39     252175 non-null  float64\n",
      " 41  S40     252175 non-null  float64\n",
      " 42  S41     252175 non-null  float64\n",
      " 43  S42     252175 non-null  float64\n",
      " 44  S43     252175 non-null  float64\n",
      " 45  S44     252175 non-null  float64\n",
      " 46  S45     252175 non-null  float64\n",
      " 47  S46     252175 non-null  float64\n",
      " 48  S47     252175 non-null  float64\n",
      " 49  S48     252175 non-null  float64\n",
      " 50  S49     252175 non-null  float64\n",
      " 51  S50     252175 non-null  float64\n",
      " 52  S51     252175 non-null  float64\n",
      " 53  S52     252175 non-null  float64\n",
      " 54  S53     252175 non-null  float64\n",
      " 55  S54     252175 non-null  float64\n",
      " 56  S55     252175 non-null  float64\n",
      " 57  S56     252175 non-null  float64\n",
      " 58  S57     252175 non-null  float64\n",
      " 59  S58     252175 non-null  float64\n",
      " 60  S59     252175 non-null  float64\n",
      " 61  S60     252175 non-null  float64\n",
      " 62  S61     252175 non-null  float64\n",
      " 63  S62     252175 non-null  float64\n",
      " 64  S63     252175 non-null  float64\n",
      " 65  S64     252175 non-null  float64\n",
      " 66  S65     252175 non-null  float64\n",
      " 67  S66     252175 non-null  float64\n",
      " 68  S67     252175 non-null  float64\n",
      " 69  S68     252175 non-null  float64\n",
      " 70  S69     252175 non-null  float64\n",
      " 71  S70     252175 non-null  float64\n",
      " 72  S71     252175 non-null  float64\n",
      " 73  S72     252175 non-null  float64\n",
      " 74  S73     252175 non-null  float64\n",
      " 75  S74     252175 non-null  float64\n",
      " 76  S75     252175 non-null  float64\n",
      " 77  S76     252175 non-null  float64\n",
      " 78  S77     252175 non-null  float64\n",
      " 79  S78     252175 non-null  float64\n",
      " 80  S79     252175 non-null  float64\n",
      " 81  S80     252175 non-null  float64\n",
      " 82  S81     252175 non-null  float64\n",
      " 83  S82     252175 non-null  float64\n",
      " 84  S83     252175 non-null  float64\n",
      " 85  S84     252175 non-null  float64\n",
      " 86  S85     252175 non-null  float64\n",
      " 87  S86     252175 non-null  float64\n",
      " 88  S87     252175 non-null  float64\n",
      " 89  S88     252175 non-null  float64\n",
      " 90  S89     252175 non-null  float64\n",
      "dtypes: float64(90), int64(1)\n",
      "memory usage: 175.1 MB\n",
      "None\n",
      "\n",
      "\n",
      "                Year             S0             S1             S2  \\\n",
      "count  252175.000000  252175.000000  252175.000000  252175.000000   \n",
      "mean     1998.350380      43.379379       1.555258       8.643927   \n",
      "std        10.497739       6.066547      51.551085      35.235495   \n",
      "min      1956.000000       3.455260    -334.953220    -301.005060   \n",
      "25%      1994.000000      39.959775     -25.651750     -11.524900   \n",
      "50%      2002.000000      44.250440       8.655610      10.516440   \n",
      "75%      2006.000000      47.822515      36.248650      29.792790   \n",
      "max      2009.000000      61.970140     384.065730     318.868960   \n",
      "\n",
      "                  S3             S4             S5             S6  \\\n",
      "count  252175.000000  252175.000000  252175.000000  252175.000000   \n",
      "mean        1.160078      -6.526075      -9.532049      -2.366866   \n",
      "std        16.336577      22.841967      12.809154      14.530697   \n",
      "min      -149.962040    -181.953370     -72.717370    -111.017810   \n",
      "25%        -8.492585     -20.587910     -18.402445     -10.770340   \n",
      "50%        -0.641920      -5.999260     -11.189750      -2.072920   \n",
      "75%         8.766685       7.739900      -2.448645       6.512925   \n",
      "max       228.412110     262.068870     166.236890     160.815220   \n",
      "\n",
      "                  S7             S8  ...            S80            S81  \\\n",
      "count  252175.000000  252175.000000  ...  252175.000000  252175.000000   \n",
      "mean       -1.788645       3.713079  ...      15.723383     -73.290415   \n",
      "std         7.963275      10.553843  ...      31.982900     174.935574   \n",
      "min       -68.404510    -119.762620  ...    -437.722030   -2984.920970   \n",
      "25%        -6.472825      -2.295965  ...      -1.788255    -139.034460   \n",
      "50%        -1.727900       3.821990  ...       9.132400     -53.168610   \n",
      "75%         2.913400       9.938425  ...      26.206820      13.411780   \n",
      "max        82.942190      92.792850  ...     840.973380    4469.454870   \n",
      "\n",
      "                 S82            S83            S84            S85  \\\n",
      "count  252175.000000  252175.000000  252175.000000  252175.000000   \n",
      "mean       41.480537      38.046821       0.334712      17.927021   \n",
      "std       122.250383      94.576578      16.020922     114.053576   \n",
      "min     -1810.689190   -1848.702260    -272.289050   -2343.894110   \n",
      "25%       -21.014560      -4.630075      -6.748720     -31.246970   \n",
      "50%        28.673440      33.597330       0.819000      15.843510   \n",
      "75%        89.181345      77.881735       8.452415      67.776640   \n",
      "max      3210.701700    1734.079690     199.121500    3662.065650   \n",
      "\n",
      "                 S86            S87            S88            S89  \n",
      "count  252175.000000  252175.000000  252175.000000  252175.000000  \n",
      "mean      -26.502617       4.487977      19.875335       1.309523  \n",
      "std       173.680285      13.286064     185.158800      22.113525  \n",
      "min     -3819.933620    -233.456480   -7458.378150    -286.031200  \n",
      "25%      -102.175470      -2.536810     -59.734690      -8.820370  \n",
      "50%       -21.613560       3.145290       7.774840       0.062980  \n",
      "75%        51.897840       9.999465      85.838080       9.651235  \n",
      "max      2833.608950     275.353660    7240.653730     600.766240  \n",
      "\n",
      "[8 rows x 91 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Visualizza il numero di righe e le colonne del dataset\n",
    "print(f'{df.shape} \\n')\n",
    "\n",
    "# Verifica informazioni sul dataset\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "\n",
    "# Statistiche descrittive\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizzazione del dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizza le features dopo l'imputazione degli outlier\n",
    "scaler = MinMaxScaler()\n",
    "df.iloc[:, 1:] = scaler.fit_transform(df.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suddivisione del dataset in variabili di input (X) e variabile di output (y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona le variabili di input (X) e output (y)\n",
    "X = df.drop(\"Year\", axis=1)\n",
    "y = df[\"Year\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suddivisione del dataset in set di addestramento (80%), validazione (10%) e test (10%)**\n",
    "\n",
    "**Test su Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance sul set di addestramento:\n",
      "MSE: 84.52654234857089\n",
      "R-squared: 0.23463947459199108\n",
      "\n",
      "Performance sul set di validazione:\n",
      "MSE: 84.18137128832679\n",
      "R-squared: 0.23228242034743962\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Creazione e addestramento del modello di regressione lineare\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Previsioni sul set di addestramento, validazione e test\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Valutazione delle prestazioni del modello\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Stampa dei risultati\n",
    "print(\"Performance sul set di addestramento:\")\n",
    "print(f'MSE: {mse_train}')\n",
    "print(f'R-squared: {r2_train}')\n",
    "\n",
    "print(\"\\nPerformance sul set di validazione:\")\n",
    "print(f'MSE: {mse_val}')\n",
    "print(f'R-squared: {r2_val}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test su Random Forest Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance sul set di addestramento:\n",
      "MSE: 11.041064189798998\n",
      "R-squared: 0.900026731786563\n",
      "\n",
      "Performance sul set di validazione:\n",
      "MSE: 78.39913993877147\n",
      "R-squared: 0.2850152350870272\n"
     ]
    }
   ],
   "source": [
    "# Suddivisione del dataset in set di addestramento, validazione e test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Creazione e addestramento del modello Random Forest\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Previsioni sul set di addestramento, validazione e test\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Valutazione delle prestazioni del modello Random Forest\n",
    "mse_train_rf = mean_squared_error(y_train, y_train_pred_rf)\n",
    "r2_train_rf = r2_score(y_train, y_train_pred_rf)\n",
    "\n",
    "mse_val_rf = mean_squared_error(y_val, y_val_pred_rf)\n",
    "r2_val_rf = r2_score(y_val, y_val_pred_rf)\n",
    "\n",
    "# Stampa dei risultati per il modello Random Forest\n",
    "print(\"Performance sul set di addestramento:\")\n",
    "print(f'MSE: {mse_train_rf}')\n",
    "print(f'R-squared: {r2_train_rf}')\n",
    "\n",
    "print(\"\\nPerformance sul set di validazione:\")\n",
    "print(f'MSE: {mse_val_rf}')\n",
    "print(f'R-squared: {r2_val_rf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test su SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance sul set di addestramento:\n",
      "MSE: 86.95411568827807\n",
      "R-squared: 0.21265858249441938\n",
      "\n",
      "Performance sul set di validazione:\n",
      "MSE: 86.16184216803947\n",
      "R-squared: 0.21422091473074234\n"
     ]
    }
   ],
   "source": [
    "# Suddivisione del dataset in set di addestramento, validazione e test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Creazione e addestramento del modello SVM\n",
    "svm_model = SVR()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Previsioni sul set di addestramento, validazione e test\n",
    "y_train_pred_svm = svm_model.predict(X_train)\n",
    "y_val_pred_svm = svm_model.predict(X_val)\n",
    "y_test_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Valutazione delle prestazioni del modello SVM\n",
    "mse_train_svm = mean_squared_error(y_train, y_train_pred_svm)\n",
    "r2_train_svm = r2_score(y_train, y_train_pred_svm)\n",
    "\n",
    "mse_val_svm = mean_squared_error(y_val, y_val_pred_svm)\n",
    "r2_val_svm = r2_score(y_val, y_val_pred_svm)\n",
    "\n",
    "# Stampa dei risultati per il modello SVM\n",
    "print(\"Performance sul set di addestramento:\")\n",
    "print(f'MSE: {mse_train_svm}')\n",
    "print(f'R-squared: {r2_train_svm}')\n",
    "\n",
    "print(\"\\nPerformance sul set di validazione:\")\n",
    "print(f'MSE: {mse_val_svm}')\n",
    "print(f'R-squared: {r2_val_svm}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test su KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance sul set di addestramento:\n",
      "MSE: 55.389613165460496\n",
      "R-squared: 0.4984649524685075\n",
      "\n",
      "Performance sul set di validazione:\n",
      "MSE: 83.83195146131577\n",
      "R-squared: 0.2354690605716374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Suddivisione del dataset in set di addestramento, validazione e test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Creazione e addestramento del modello KNN\n",
    "knn_model = KNeighborsRegressor()\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Previsioni sul set di addestramento, validazione e test\n",
    "y_train_pred_knn = knn_model.predict(X_train)\n",
    "y_val_pred_knn = knn_model.predict(X_val)\n",
    "y_test_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Valutazione delle prestazioni del modello KNN\n",
    "mse_train_knn = mean_squared_error(y_train, y_train_pred_knn)\n",
    "r2_train_knn = r2_score(y_train, y_train_pred_knn)\n",
    "\n",
    "mse_val_knn = mean_squared_error(y_val, y_val_pred_knn)\n",
    "r2_val_knn = r2_score(y_val, y_val_pred_knn)\n",
    "\n",
    "# Stampa dei risultati per il modello KNN\n",
    "print(\"Performance sul set di addestramento:\")\n",
    "print(f'MSE: {mse_train_knn}')\n",
    "print(f'R-squared: {r2_train_knn}')\n",
    "\n",
    "print(\"\\nPerformance sul set di validazione:\")\n",
    "print(f'MSE: {mse_val_knn}')\n",
    "print(f'R-squared: {r2_val_knn}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ricerca iperparametri su Random Forest Regression**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Creazione e addestramento del modello Random Forest con Randomized Search\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "random_search_rf = RandomizedSearchCV(rf_model, param_dist_rf, n_iter=10, scoring='neg_mean_squared_error', cv=5, random_state=42)\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Ottieni il miglior modello dalla ricerca degli iperparametri\n",
    "best_rf_model = random_search_rf.best_estimator_\n",
    "\n",
    "# Valutazione delle prestazioni del modello ottimizzato sul set di validazione\n",
    "y_val_pred_rf_best = best_rf_model.predict(X_val)\n",
    "mse_val_rf_best = mean_squared_error(y_val, y_val_pred_rf_best)\n",
    "r2_val_rf_best = r2_score(y_val, y_val_pred_rf_best)\n",
    "\n",
    "# Stampa dei risultati per il modello Random Forest ottimizzato sul set di validazione\n",
    "print(\"\\nPerformance sul set di validazione con Random Forest ottimizzato:\")\n",
    "print(f'MSE: {mse_val_rf_best}')\n",
    "print(f'R-squared: {r2_val_rf_best}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ricerca iperparametri su SVM**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci i parametri da testare per KNN\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Creazione del modello KNN\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# Creazione dell'oggetto GridSearchCV\n",
    "grid_search_knn = GridSearchCV(knn_model, param_grid_knn, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Esecuzione della ricerca degli iperparametri sul set di addestramento\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Ottieni i migliori iperparametri trovati\n",
    "best_params_knn = grid_search_knn.best_params_\n",
    "\n",
    "# Stampare i migliori parametri trovati\n",
    "print(\"Migliori parametri per KNN:\", best_params_knn)\n",
    "\n",
    "# Previsioni con il miglior modello trovato\n",
    "y_val_pred_knn_best = grid_search_knn.predict(X_val)\n",
    "\n",
    "# Valutazione delle prestazioni del modello migliorato\n",
    "mse_val_knn_best = mean_squared_error(y_val, y_val_pred_knn_best)\n",
    "r2_val_knn_best = r2_score(y_val, y_val_pred_knn_best)\n",
    "\n",
    "# Stampa dei risultati per il modello migliorato\n",
    "print(\"\\nPerformance sul set di validazione con KNN ottimizzato:\")\n",
    "print(f'MSE: {mse_val_knn_best}')\n",
    "print(f'R-squared: {r2_val_knn_best}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
